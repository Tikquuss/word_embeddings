{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW&TF-IDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tikquuss/word_embeddings/blob/main/BOW%26TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FeOQWTMgh2A"
      },
      "source": [
        "For the parts ```Bag of words``` and ```TF-IDF```, I was inspired by the [moocs  of coursera](https://www.coursera.org/learn/language-processing/home/week/1) that I followed recently.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHJbYbK2gUo5",
        "outputId": "47600370-fa5e-4d2b-b2dd-660e5d9f242b"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pickle\r\n",
        "\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEvvq1Za-YGd"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSJ2Q7-ggDoW",
        "outputId": "9d331871-ae02-4051-bbd6-bf4f5ad26bdd"
      },
      "source": [
        "! wget -c https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-05 21:42:35--  https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65862309 (63M) [text/plain]\n",
            "Saving to: ‘IMDb_Reviews.csv’\n",
            "\n",
            "IMDb_Reviews.csv    100%[===================>]  62.81M   196MB/s    in 0.3s    \n",
            "\n",
            "2021-01-05 21:42:36 (196 MB/s) - ‘IMDb_Reviews.csv’ saved [65862309/65862309]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnL4OL0h5Fy"
      },
      "source": [
        "data_frame = pd.read_csv('/content/IMDb_Reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RnAIz07yo97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ac67aa-c302-4fed-e6a0-d0bb41800040"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o94SC9SiNxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1d238cc1-5527-4a86-ca39-76cbb6972601"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHiR8DmaKxPS"
      },
      "source": [
        "**Summary of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ1TmBvn0Xu6"
      },
      "source": [
        "#df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0aqX7hy0n1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d266da1-a93d-4dc5-c57b-7bffc42ca2c5"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp_lxOCa1moi"
      },
      "source": [
        "# **Spliting the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjnuSjRLxdTy"
      },
      "source": [
        "X, y = df['review'].values, df['sentiment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsvQeU26XSp"
      },
      "source": [
        "seed = 1234 # For reproducibility\n",
        "test_ratio = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY0ccKUC5jU5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ratio, random_state = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66f76VSUDh7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f919314-e99a-4030-af46-da9cec1d59e1"
      },
      "source": [
        "len(X_train), len(X_test),"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvSA6tae9gDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "80a147cb-edcb-4539-82f7-9a2e53372b85"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Basically, this movie is one of those rare movies you either hate and think borders on suicide as the next best thing to do, rather than having to sit through it for two hours. Or, as in my case, you see it as a kult hit, one of those movies wherein the humour, the plot, the acting, is actually very hidden but for those of us willing to go looking for it, trusting the director well, the reward is: U laugh your A.. of !! The fact that U have to find the things mentioned above, actually makes the movie even more funny, because u get the impression the director isn't even aware of how funny his movie is, which doesn't seem likely and therein lies the intelligence at the helm of this magnificient project called : Spaced Invaders !!\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAWub7U7Usi"
      },
      "source": [
        "# **Text Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9mG5ahh7VKe"
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def text_prepare(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = re.sub(BAD_SYMBOLS_RE, '', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyH8v-FJ7yb_"
      },
      "source": [
        "a = X_train[0]\n",
        "X_train = [text_prepare(x) for x in X_train]\n",
        "X_test = [text_prepare(x) for x in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ATJDGq74Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c13788-c802-48cd-f83c-e5128254d5f4"
      },
      "source": [
        "print(a)\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basically, this movie is one of those rare movies you either hate and think borders on suicide as the next best thing to do, rather than having to sit through it for two hours. Or, as in my case, you see it as a kult hit, one of those movies wherein the humour, the plot, the acting, is actually very hidden but for those of us willing to go looking for it, trusting the director well, the reward is: U laugh your A.. of !! The fact that U have to find the things mentioned above, actually makes the movie even more funny, because u get the impression the director isn't even aware of how funny his movie is, which doesn't seem likely and therein lies the intelligence at the helm of this magnificient project called : Spaced Invaders !!\n",
            "basically movie one rare movies either hate think borders suicide next best thing rather sit two hours case see kult hit one movies wherein humour plot acting actually hidden us willing go looking trusting director well reward u laugh fact u find things mentioned actually makes movie even funny u get impression director isnt even aware funny movie doesnt seem likely therein lies intelligence helm magnificient project called spaced invaders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKtrEzO49Iyj"
      },
      "source": [
        "# **Transforming text to a vector**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_KXBgX29i6B"
      },
      "source": [
        "## **1) Bag of words**   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVN1PcNiAgSI"
      },
      "source": [
        "\n",
        "\n",
        "1. Find *N* most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.\n",
        "2. For each title in the corpora create a zero vector with the dimension equals to *N*.\n",
        "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate.  \n",
        "\n",
        "Drawbacks : \n",
        "- vocabulary size\n",
        "- contain many 0s (thereby resulting in a sparse matrix)\n",
        "- We are retaining no information on the grammar of the sentences nor on the ordering of the words in the text.\n",
        "\n",
        "\n",
        "Let's try to do it for a toy example. Imagine that we have *N* = 4 and the list of the most popular words is \n",
        "\n",
        "    ['hi', 'you', 'me', 'are']\n",
        "\n",
        "Then we need to numerate them, for example, like this: \n",
        "\n",
        "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
        "\n",
        "And we have the text, which we want to transform to the vector:\n",
        "\n",
        "    'hi how are you'\n",
        "\n",
        "For this text we create a corresponding zero vector \n",
        "\n",
        "    [0, 0, 0, 0]\n",
        "    \n",
        "And iterate over all words, and if the word is in the dictionary, we increase the value of the corresponding position in the vector:\n",
        "\n",
        "    'hi':  [1, 0, 0, 0]\n",
        "    'how': [1, 0, 0, 0] # word 'how' is not in our dictionary\n",
        "    'are': [1, 0, 0, 1]\n",
        "    'you': [1, 1, 0, 1]\n",
        "\n",
        "The resulting vector will be \n",
        "\n",
        "    [1, 1, 0, 1]\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQjwERoxAqiT"
      },
      "source": [
        "To find the most common words use train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPJlp4WnLWTn"
      },
      "source": [
        "**Words counts and most common words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLzGKs6LaeB"
      },
      "source": [
        "words_counts = {}\n",
        "for line in X_train:\n",
        "  word_list = line.split()\n",
        "  for word in word_list: \n",
        "    words_counts[word] = words_counts.get(word, 0) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNsEwfqLeNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78b4d13-4413-47f4-e578-c52b0546b705"
      },
      "source": [
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "print(most_common_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('br', 94212), ('movie', 66976), ('film', 60162), ('one', 41018), ('like', 31214), ('good', 22955), ('even', 19621), ('would', 19229), ('time', 18757), ('really', 18386)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoavvBFxD_7s"
      },
      "source": [
        "DICT_SIZE = 10000 # size of the dictionary\n",
        "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(sorted(words_counts.keys(), key=lambda x: words_counts[x], reverse=True)[:DICT_SIZE], 0)}\n",
        "INDEX_TO_WORDS = {y:x for x,y in WORDS_TO_INDEX.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twA0zTPVAPlU"
      },
      "source": [
        "def my_bag_of_words(text, words_to_index, dict_size):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        dict_size: size of the dictionary\n",
        "        \n",
        "        return a vector which is a bag-of-words representation of 'text'\n",
        "    \"\"\"\n",
        "    result_vector = np.zeros(dict_size)\n",
        "    for item in text.split():\n",
        "        if item in words_to_index.keys():\n",
        "            result_vector[words_to_index[item]] += 1\n",
        "    return result_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CKPzOhuiCbn",
        "outputId": "fe5f3e56-0d25-4b83-9b8f-d86c20d78313"
      },
      "source": [
        "my_bag_of_words(X_train[0], WORDS_TO_INDEX, DICT_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 3., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE9NNIBVBPLt"
      },
      "source": [
        "Now apply the implemented function to all samples.  \n",
        "We use [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) (Compressed Sparse Row matrix) for fast matrix vector products and [scipy.sparse.vstack](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.html#scipy.sparse.vstack)  to Stack sparse matrices vertically (row wise)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLpV_HCDBEcd"
      },
      "source": [
        "# sparse matrix package for numeric data.\n",
        "from scipy import sparse as sp_sparse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSo252G9BHY7"
      },
      "source": [
        "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
        "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOa0j9DaoM5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c79743-ec27-42fc-fbcf-db8d3861d23b"
      },
      "source": [
        "print('X_train shape ', X_train_mybag.shape)\n",
        "print('X_test shape ', X_test_mybag.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape  (40000, 10000)\n",
            "X_test shape  (10000, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxnxl1wvEgMp"
      },
      "source": [
        "## 2) **TF-IDF (Term Frequency-Inverse Document Frequency)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0TTdyVXlZ6g"
      },
      "source": [
        "TF-IDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\t\r\n",
        "\r\n",
        "- *Term Frequency (TF)* : It is a measure of how frequently a term, $t$, appears in a document, $d$:\t\r\n",
        "$$tf (t, d) = \\frac{\\text{number of times the term “t” appears in the document “d”}}{\\text{number of terms in the document \"d\"}}$$\r\n",
        "\r\n",
        "- *Inverse Document Frequency (IDF)* : IDF is a measure of how important a term is. We need the IDF value because computing just the TF alone is not sufficient to understand the importance of words.\r\n",
        "\r\n",
        "$$idf (t) = log \\bigg( \\frac{\\text{numbers of document}}{\\text{number of document with the term \"t\"}} \\bigg)$$\r\n",
        "\r\n",
        "- We can now compute the TF-IDF score for each word in the corpus. Words with a higher score are more important, and those with a lower score are less important.\r\n",
        "\r\n",
        "$$tf\\_idf(t, d) = tf (t, d) * idf (t)$$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWm8CHowFSgb"
      },
      "source": [
        "TF-IDF takes into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. \n",
        "\n",
        "- We use class [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) from *scikit-learn*. \n",
        "- We use *train* corpus to train a vectorizer. \n",
        "- Our filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the titles)\n",
        "- We use bigrams along with unigrams in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DUGtA-qGfHo"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4cKTPq_G7R_"
      },
      "source": [
        "How is it work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgGwTw_FRDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b43621-506a-401f-db1c-8573abbb97d2"
      },
      "source": [
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_dummy = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.get_feature_names()) \n",
        "print(X_dummy.shape)\n",
        "print(X_dummy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "(4, 9)\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHxlneWWHet2"
      },
      "source": [
        "def tfidf_features(X_train, X_test):\n",
        "    \"\"\"\n",
        "        X_train, X_test — samples        \n",
        "        return TF-IDF vectorized representation of each sample and vocabulary\n",
        "    \"\"\"\n",
        "    # Create TF-IDF vectorizer with a proper parameters choice\n",
        "    # Fit the vectorizer on the train set\n",
        "    # Transform the train and test sets and return the result\n",
        "    \n",
        "    \n",
        "    tfidf_vectorizer = TfidfVectorizer(\n",
        "        lowercase = True, \n",
        "        min_df=5, \n",
        "        max_df=0.9, \n",
        "        ngram_range=(1, 2), \n",
        "        #token_pattern='(\\S+)' # todo\n",
        "    )\n",
        "    \n",
        "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "    X_test = tfidf_vectorizer.transform(X_test)\n",
        "    \n",
        "    return X_train, X_test, tfidf_vectorizer, tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVIJYqrjIF1c"
      },
      "source": [
        "X_train_tfidf, X_test_tfidf, tfidf_vectorizer, tfidf_vocab = tfidf_features(X_train, X_test)\n",
        "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quNoRYtdxQxz",
        "outputId": "b2b4a0b5-89b6-4f53-8fe2-d999631bd57b"
      },
      "source": [
        "print(tfidf_vectorizer.transform([X_train[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 141685)\t0.13766236349138156\n",
            "  (0, 141675)\t0.0893839369132375\n",
            "  (0, 141017)\t0.12594728983001974\n",
            "  (0, 140062)\t0.037648472901724864\n",
            "  (0, 135446)\t0.05220524424041844\n",
            "  (0, 133749)\t0.09541472954660453\n",
            "  (0, 133619)\t0.04380564551985267\n",
            "  (0, 132820)\t0.1341276887781818\n",
            "  (0, 128269)\t0.04173390750443947\n",
            "  (0, 128072)\t0.05149263147285057\n",
            "  (0, 127810)\t0.04801861800733908\n",
            "  (0, 127533)\t0.13639775235602547\n",
            "  (0, 127532)\t0.12694346361735465\n",
            "  (0, 124122)\t0.09064994063599877\n",
            "  (0, 119784)\t0.13976290036945693\n",
            "  (0, 117283)\t0.07635550509899132\n",
            "  (0, 112639)\t0.16111250408393288\n",
            "  (0, 112583)\t0.05910500108832005\n",
            "  (0, 111844)\t0.03513215105565094\n",
            "  (0, 106803)\t0.11794474007926736\n",
            "  (0, 103247)\t0.15638535971459747\n",
            "  (0, 103134)\t0.05641522903117024\n",
            "  (0, 103055)\t0.14605616589456188\n",
            "  (0, 103040)\t0.08514258494068441\n",
            "  (0, 101203)\t0.0831683934229732\n",
            "  :\t:\n",
            "  (0, 47650)\t0.04933971841386271\n",
            "  (0, 42601)\t0.15857952553589774\n",
            "  (0, 42544)\t0.05204299770481386\n",
            "  (0, 39893)\t0.11698354005840478\n",
            "  (0, 39699)\t0.1497228239284068\n",
            "  (0, 39656)\t0.06933658085734155\n",
            "  (0, 36783)\t0.151152580524983\n",
            "  (0, 36749)\t0.06190574233938355\n",
            "  (0, 34042)\t0.09905628163961787\n",
            "  (0, 33896)\t0.04845690214755875\n",
            "  (0, 33089)\t0.1497228239284068\n",
            "  (0, 32858)\t0.09976859806984359\n",
            "  (0, 20309)\t0.16111250408393288\n",
            "  (0, 20258)\t0.06515597366219504\n",
            "  (0, 19114)\t0.0665698002186698\n",
            "  (0, 15072)\t0.12051074745264956\n",
            "  (0, 12862)\t0.09995864831160356\n",
            "  (0, 12588)\t0.04360906169984562\n",
            "  (0, 11217)\t0.13167060798669009\n",
            "  (0, 11200)\t0.07258519565434778\n",
            "  (0, 9497)\t0.09256184793412511\n",
            "  (0, 3034)\t0.12728940976511652\n",
            "  (0, 2902)\t0.09799274424925336\n",
            "  (0, 1870)\t0.13522355044504836\n",
            "  (0, 1861)\t0.042078508569573146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsvBNyOIxt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686184db-7183-441c-81f5-33db53c0f4f7"
      },
      "source": [
        "print('X_train_tfidf shape ', X_train_tfidf.shape)\n",
        "print('X_test_tfidf shape ', X_test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_tfidf shape  (40000, 146247)\n",
            "X_test_tfidf shape  (10000, 146247)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-S3-r7IPgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3682950e-fe10-40aa-f0c9-373ace35912f"
      },
      "source": [
        "assert list(tfidf_vocab.keys())[:10] == list(tfidf_reversed_vocab.values())[:10], \"An error occurred\"\n",
        "list(tfidf_vocab.keys())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['basically',\n",
              " 'movie',\n",
              " 'one',\n",
              " 'rare',\n",
              " 'movies',\n",
              " 'either',\n",
              " 'hate',\n",
              " 'think',\n",
              " 'borders',\n",
              " 'suicide']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdgYGVKWJqCU"
      },
      "source": [
        "# **Classifiers**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hPQU5OKORN"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtGOiKveG6AC"
      },
      "source": [
        "## **Exhaustive search over specified parameter values for an estimator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q4_V7i6IEr1"
      },
      "source": [
        "parameters = {'C': np.linspace(start = 0.0001, stop = 100, num=100)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7DpU0QCIW2s"
      },
      "source": [
        "grid_search_mybag = GridSearchCV(LogisticRegression(), parameters, n_jobs = -1)\n",
        "grid_search_tfidf = GridSearchCV(LogisticRegression(), parameters, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxqgUwtGIpzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fe357c-6b24-495b-c8a4-11ff115b8116"
      },
      "source": [
        "grid_search_mybag.fit(X_train_mybag, y_train)\n",
        "grid_search_tfidf.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.00000e-04, 1.010...\n",
              "       7.57576e+01, 7.67677e+01, 7.77778e+01, 7.87879e+01, 7.97980e+01,\n",
              "       8.08081e+01, 8.18182e+01, 8.28283e+01, 8.38384e+01, 8.48485e+01,\n",
              "       8.58586e+01, 8.68687e+01, 8.78788e+01, 8.88889e+01, 8.98990e+01,\n",
              "       9.09091e+01, 9.19192e+01, 9.29293e+01, 9.39394e+01, 9.49495e+01,\n",
              "       9.59596e+01, 9.69697e+01, 9.79798e+01, 9.89899e+01, 1.00000e+02])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7kWiT2-GkrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35d5ce1-3d14-428c-d092-63d7e6d9619d"
      },
      "source": [
        "print('best parameters mybag: ', grid_search_mybag.best_params_)\n",
        "print('best scrores mybag: ', grid_search_mybag.best_score_)\n",
        "\n",
        "print('best parameters tfidf: ', grid_search_tfidf.best_params_)\n",
        "print('best scrores tfidf: ', grid_search_tfidf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters mybag:  {'C': 1.0102}\n",
            "best scrores mybag:  0.8708500000000001\n",
            "best parameters tfidf:  {'C': 9.091}\n",
            "best scrores tfidf:  0.9049250000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGDF3yFhuaMw"
      },
      "source": [
        "C_mybag = 1.0102\n",
        "C_tfidf = 0.9049250000000001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZHMps8hOE9a"
      },
      "source": [
        "Train the classifiers for different data transformations: *bag-of-words*, *tf-idf* and *bert*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUFM8QhmKxiG"
      },
      "source": [
        "classifier_mybag = LogisticRegression(penalty = \"l2\", C = C_mybag, solver = \"newton-cg\", random_state = 0, n_jobs = -1).fit(\n",
        "    X_train_mybag, y_train\n",
        ")\n",
        "\n",
        "classifier_tfidf = LogisticRegression(penalty = \"l2\", C = C_tfidf, solver = \"newton-cg\", random_state = 0, n_jobs = -1).fit(\n",
        "    X_train_tfidf, \n",
        "    y_train\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itetoF3cOJDF"
      },
      "source": [
        "Create predictions for the data : labels and scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdgM_f_nK12P"
      },
      "source": [
        "y_test_predicted_labels_mybag = classifier_mybag.predict(X_test_mybag)\n",
        "y_test_predicted_scores_mybag = classifier_mybag.decision_function(X_test_mybag)\n",
        "\n",
        "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
        "y_test_predicted_scores_tfidf = classifier_tfidf.decision_function(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCzbiZkdvjgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb1377b-828a-400a-9719-b6dd46fb254f"
      },
      "source": [
        "print('===== Bag-of-words : ', classifier_mybag.score(X_test_mybag, y_test))\n",
        "print('===== Tfidf : ', classifier_tfidf.score(X_test_tfidf, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Bag-of-words :  0.8765\n",
            "===== Tfidf :  0.9024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMuZaV1xOgj0"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "To evaluate the results we will use several classification metrics:\n",
        " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOe1RvfIMhnk"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOLUDebPAk8"
      },
      "source": [
        "def print_evaluation_scores(y, predicted):\n",
        "    print(\"accuracy_score : \", accuracy_score(y, predicted))\n",
        "    print(\"f1_score : \", f1_score(y, predicted, average=\"macro\"))\n",
        "    print(\"recall_score : \", recall_score(y, predicted, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVpbDzSFPEcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726c0be2-2552-4b75-82bf-6f5857672ba2"
      },
      "source": [
        "print('===== Bag-of-words')\n",
        "print_evaluation_scores(y_test, y_test_predicted_labels_mybag)\n",
        "print('===== Tfidf')\n",
        "print_evaluation_scores(y_test, y_test_predicted_labels_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Bag-of-words\n",
            "accuracy_score :  0.8765\n",
            "f1_score :  0.8764981215364286\n",
            "recall_score :  0.8764965821550783\n",
            "===== Tfidf\n",
            "accuracy_score :  0.9024\n",
            "f1_score :  0.9023864082834894\n",
            "recall_score :  0.9023871394374807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5nDMbNNKsoj"
      },
      "source": [
        "### **Deploy model with gradio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1d9utOjK9eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3953b62c-c63e-4236-9c3c-dad3471a7744"
      },
      "source": [
        "! pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/c6/0c18e033cd293c603266e33212df6da3ae4cc3b84e7e91317bce9cffffa9/gradio-1.4.0-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gradio) (2.23.0)\n",
            "Collecting paramiko\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.19.4)\n",
            "Collecting markdown2\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/d2/6e6ab0d9387c332bf1de205522a8386b48e2dddf332ba6ad71b2ec371110/markdown2-2.3.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from gradio) (1.1.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from gradio) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from gradio) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from gradio) (1.1.5)\n",
            "Collecting Flask-Cors>=3.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from gradio) (0.16.2)\n",
            "Collecting analytics-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/37/c49d052f88655cd96445c36979fb63f69ef859e167eaff5706ca7c8a8ee3/analytics_python-1.2.9-py2.py3-none-any.whl\n",
            "Collecting flask-cachebuster\n",
            "  Downloading https://files.pythonhosted.org/packages/74/47/f3e1fedfaad965c81c2f17234636d72f71450f1b4522ca26d2b7eb4a0a74/Flask-CacheBuster-1.0.0.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (1.24.3)\n",
            "Collecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 26.6MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.1.1->gradio) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (51.0.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->gradio) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->gradio) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->gradio) (2018.9)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from Flask-Cors>=3.0.8->gradio) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (7.0.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.6/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.1.1->gradio) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->gradio) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->gradio) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->gradio) (0.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (2.4.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
            "Building wheels for collected packages: flask-cachebuster\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-cp36-none-any.whl size=3374 sha256=156e38438cdbe515ea7ac961f3edcae01487ad1ff0481a1faa4f0985b5f6cfd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/fc/a7/ab5712c3ace9a8f97276465cc2937316ab8063c1fea488ea77\n",
            "Successfully built flask-cachebuster\n",
            "Installing collected packages: bcrypt, cryptography, pynacl, paramiko, markdown2, Flask-Cors, analytics-python, flask-cachebuster, gradio\n",
            "Successfully installed Flask-Cors-3.0.9 analytics-python-1.2.9 bcrypt-3.2.0 cryptography-3.3.1 flask-cachebuster-1.0.0 gradio-1.4.0 markdown2-2.3.10 paramiko-2.7.2 pynacl-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxcy7apPLVWq"
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9tSnqTLXv-"
      },
      "source": [
        "def mybag_predict(eula):\n",
        "    vec = my_bag_of_words(text_prepare(eula) , WORDS_TO_INDEX, DICT_SIZE)\n",
        "    output = classifier_mybag.predict([vec])[0]\n",
        "    return \"Positive\" if output == 1 else \"Negative\"\n",
        "\n",
        "def tfidf_predict(eula):\n",
        "    vec = tfidf_vectorizer.transform([text_prepare(eula)])\n",
        "    output = classifier_tfidf.predict(vec)[0]\n",
        "    return \"Positive\" if output == 1 else \"Negative\"\n",
        "\n",
        "def predict(model_name, eula):\n",
        "  if model_name == \"Bag of word\":\n",
        "    return mybag_predict(eula)\n",
        "  elif model_name == \"TD-IDF\":\n",
        "    return tfidf_predict(eula)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijgkud5PikJx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_TRVcECLf39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "fbff901b-bb79-4009-d10c-783cbf1b7507"
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your review\", label = \"Review\", lines=10)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = mybag_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 24 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://12241.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://12241.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f7774a85048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://12241.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QluOp4_Fiy3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "548364e8-5524-4686-d059-afa23bcf9637"
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your review\", label = \"Review\", lines=10)\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = tfidf_predict, inputs = inputs, outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 24 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://36240.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://36240.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f776b368f28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://36240.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzIEBU2K6_pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "7cff1603-b101-43e4-af3c-8a40b1ae3374"
      },
      "source": [
        "inputs = gr.inputs.Textbox(placeholder=\"Your review\", label = \"Review\", lines=10)\n",
        "model_name = gr.inputs.Dropdown([\"Bag of word\", \"TD-IDF\"], label = \"model name\")\n",
        "output = gr.outputs.Textbox()\n",
        "gr.Interface(fn = predict, inputs = [model_name, inputs], outputs = output).launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 24 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://12189.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://12189.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f7777020e80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7863/',\n",
              " 'https://12189.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}